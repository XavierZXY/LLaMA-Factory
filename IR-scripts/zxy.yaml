### 基于官方配置的2K分辨率版本 - Qwen2.5-VL-7B 8GPU训练配置
### model - 模型配置
model_name_or_path: /wekafs/takisobe/zxy/models/Qwen2.5-VL-7B-Instruct  # 预训练模型路径
image_max_pixels: 16777216  # 图像最大像素数，支持4K+分辨率 (4096x4096=16M像素)
video_max_pixels: 262144    # 视频最大像素数，512x512帧
trust_remote_code: true     # 允许执行模型中的自定义代码
  #streaming: true
### method - 训练方法配置
stage: sft                  # 训练阶段：sft=监督微调, pt=预训练, dpo=偏好优化
do_train: true              # 启用训练模式
finetuning_type: lora       # 微调类型：lora=低秩适应, full=全参数微调, freeze=冻结微调
lora_rank: 32              # LoRA秩，大幅提升适配器参数量和表达能力
lora_alpha: 64            # LoRA缩放因子，设为rank的2倍，控制LoRA的影响强度
lora_target: all            # LoRA应用目标：all=所有线性层, 或指定具体层名
  #lora_dropout: 0.05          # LoRA层的dropout率，防止过拟合
  #use_rslora: true            # 使用rsLoRA优化，提升LoRA性能

### dataset - 数据集配置
dataset: la1,la2          # 数据集名称，在dataset_info.json中定义
template: qwen2_vl          # 对话模板，必须与模型匹配
media_dir: /wekafs/takisobe/haisenhe/DataPipeline  # 媒体文件(图像/视频)根目录
cutoff_len: 131072          # 最大序列长度，支持超长序列 (128K tokens)
  #max_samples: 500000         # 最大训练样本数，充分利用大数据集
overwrite_cache: true       # 覆盖已有的数据缓存，确保使用最新数据
preprocessing_num_workers: 64  # 数据预处理并行进程数，利用CPU多核加速
dataloader_num_workers: 64     # 数据加载并行进程数，减少GPU等待时间

### output - 输出配置
output_dir: /wekafs/takisobe/zxy/models/sft/qwen-ir # 模型保存目录
logging_steps: 1            # 每5步记录一次训练日志
save_steps: 20             # 每500步保存一次模型检查点
plot_loss: true             # 生成损失曲线图
overwrite_output_dir: true  # 覆盖已有的输出目录
save_only_model: false      # 保存完整训练状态，不只是模型权重
report_to: wandb            # 实验跟踪工具：wandb, tensorboard, none等

### train - 训练超参数配置
per_device_train_batch_size: 4 # 每张GPU的批次大小，充分利用256GB显存，总batch_size = 32*8=256
gradient_accumulation_steps: 2  # 梯度累积步数，有效batch_size = 256*4=1024
learning_rate: 2.0e-4          # 学习率，控制参数更新幅度
num_train_epochs: 3.0            # 训练轮数，遍历数据集的次数
lr_scheduler_type: cosine        # 学习率调度器：cosine=余弦退火, linear=线性衰减
warmup_ratio: 0.1                # 预热比例，前10%步数学习率从0增加到设定值
weight_decay: 0.001
max_grad_norm: 1.0
bf16: true                       # 使用bfloat16混合精度，节省显存并加速训练
ddp_timeout: 180000000           # 分布式训练超时时间(毫秒)
resume_from_checkpoint: null     # 从检查点恢复训练，null表示从头开始
gradient_checkpointing: true    # 关闭梯度检查点，用显存换速度（256GB显存充足）
dataloader_pin_memory: true      # 启用内存锁定，加速数据传输
remove_unused_columns: false     # 保留所有数据列，多模态训练必需

### advanced - 高级优化配置
#flash_attn: fa2                  # 使用FlashAttention-2加速注意力计算
#enable_liger_kernel: true        # 启用Liger Kernel优化，提升训练效率
#neftune_noise_alpha: 5           # NEFTune噪声增强，提升模型泛化能力

## eval - 验证配置
val_size: 300                   # 验证集比例，5%数据用于验证（节省显存给训练）
per_device_eval_batch_size: 4   # 每张GPU的验证批次大小，充分利用显存
eval_strategy: steps             # 验证策略：steps=按步数验证, epoch=按轮数验证
eval_steps: 20                  # 每500步进行一次验证评估